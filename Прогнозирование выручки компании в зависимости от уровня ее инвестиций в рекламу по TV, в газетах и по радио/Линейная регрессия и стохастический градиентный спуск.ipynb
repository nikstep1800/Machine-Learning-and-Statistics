{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recomend from pydata.org\n",
    "# Warning: We recommend using DataFrame.to_numpy() instead values(). \n",
    "\n",
    "X = adver_data.loc['1':'200', ['TV', 'Radio', 'Newspaper']].to_numpy()\n",
    "Y = adver_data.loc['1':'200', ['Sales']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = X.mean(axis = 0), X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = (X - means) / stds\n",
    "\n",
    "for i in range (X.shape[0]):\n",
    "    for j in range (X.shape[1]):\n",
    "        if j == 0:\n",
    "            X[i, j] = (X[i, j] - means[0])/stds[0]\n",
    "        elif j == 1:\n",
    "            X[i, j] = (X[i, j] - means[1])/stds[1]\n",
    "        else: \n",
    "            X[i, j] = (X[i, j] - means[2])/stds[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ones = np.ones((200, 1))\n",
    "# X = np.hstack((X, ones))\n",
    "# X.reshape(200,4)\n",
    "X = np.hstack((X, np.ones((200, 1)))).reshape(200, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.sum((y - y_pred) ** 2) / y.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(Y, np.median(Y))\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):    \n",
    "    a = np.dot(X.T, X) \n",
    "    b = np.dot(X.T, y)\n",
    "    res = np.linalg.solve(a, b)\n",
    "    return res\n",
    "#def normal_equation(X, y):\n",
    "    #return np.linalg.pinv(X).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.91925365]\n",
      " [ 2.79206274]\n",
      " [-0.02253861]\n",
      " [14.0225    ]]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, Y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0225]\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([0, 0, 0, 1], norm_eq_weights)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784126314510936\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(Y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01): \n",
    "    #массив градиента для каждого параметра\n",
    "    grad = np.zeros( (X.shape[1], 1) )\n",
    "    \n",
    "    #перевод строки параметров в столбец для поэлементного умножения\n",
    "    xRowToCol = X[train_ind].reshape(-1, 1)\n",
    "    \n",
    "    #вычисление градиента для каждого параметра\n",
    "    for i in range(X.shape[1]):\n",
    "        grad[i] = xRowToCol[i] * ( np.sum(xRowToCol * w) - y[train_ind])\n",
    "        \n",
    "    return (2 * eta / X.shape[0]) * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        w_old = w\n",
    "        w = w_old - stochastic_gradient_step(X, y, w, random_ind, eta = eta)\n",
    "        weight_dist = np.linalg.norm(w_old - w)\n",
    "        \n",
    "        errors.append(mserror(y, linear_prediction(X, w)))  \n",
    "        \n",
    "        iter_num += 1\n",
    "\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[[ 3.91069256e+00]\n",
      " [ 2.78209808e+00]\n",
      " [-8.10462217e-03]\n",
      " [ 1.40190566e+01]]\n",
      "2.784412588406704\n",
      "2.784412588406704\n",
      "CPU times: user 9.13 s, sys: 23.1 ms, total: 9.15 s\n",
      "Wall time: 9.11 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, Y, np.zeros( (X.shape[1], 1) ), max_iter = 1e5)\n",
    "\n",
    "# Посмотрим, чему равна ошибка на \n",
    "# первых 50 итерациях стохастического градиентного спуска. \n",
    "# Видим, что ошибка не обязательно уменьшается на каждой итерации.\n",
    "\n",
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')\n",
    "\n",
    "# Теперь посмотрим на зависимость ошибки от номера итерации для \n",
    "# 10^5 итераций стохастического градиентного спуска.\n",
    "# Видим, что алгоритм сходится.\n",
    "\n",
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "axis([0, 1e5, 0, 250])\n",
    "grid(True)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')\n",
    "\n",
    "# Посмотрим на вектор весов, к которому сошелся метод.\n",
    "print(stoch_grad_desc_weights)\n",
    "\n",
    "# Посмотрим на среднеквадратичную ошибку на последней итерации.\n",
    "print(stoch_errors_by_iter[-1])\n",
    "\n",
    "# Какова среднеквадратичная ошибка прогноза значений Sales в виде\n",
    "# линейной модели с весами, найденными с помощью градиентного спуска? \n",
    "# Запишите ответ в файл '4.txt'.\n",
    "answer4 = mserror(Y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(answer4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
